
# ğŸŒ Kenya Clinical Reasoning Challenge ğŸ©º

[![Zindi](https://img.shields.io/badge/Zindi-Challenge-orange)](https://zindi.africa/competitions/kenya-clinical-reasoning-challenge)
[![Leaderboard](https://zindi.africa/competitions/kenya-clinical-reasoning-challenge/leaderboard)
[![Python](https://img.shields.io/badge/Python-3.x-blue)](https://www.python.org/)


---

## ğŸ“œ Overview
This project was developed for the **[Kenya Clinical Reasoning Challenge](https://zindi.africa/competitions/kenya-clinical-reasoning-challenge)** hosted on Zindi.  
The goal was to **predict clinician responses** to medical prompts â€” pushing the boundaries of AI-assisted healthcare reasoning.

The project aimed to surpass baseline LLMs such as **GPT-4.0, LLAMA, and GEMINI** using a **ROUGE score** evaluation.

---

## ğŸ¯ Objective
> Build a text-to-text generation model capable of reasoning like a clinician â€” and aim for **0.50+** ROUGE score.

---

## ğŸ› ï¸ Approach
### **Step 1 â€” Data Exploration**
ğŸ” Investigated dataset structure, prompts, and clinician answers.

### **Step 2 â€” Preprocessing**
ğŸ§¹ Cleaned and tokenized text, handled missing values, created paired training data.

### **Step 3 â€” Model Selection**
âš™ï¸ Chose a **Transformer-based model** optimized for clinical reasoning tasks.

### **Step 4 â€” Training**
ğŸ’» Trained on GPU with tuned hyperparameters to prevent overfitting.

### **Step 5 â€” Evaluation**
ğŸ“Š Measured **ROUGE scores** on public and private leaderboards.

### **Step 6 â€” Submission**
ğŸ“‚ Prepared predictions in Zindiâ€™s required format.

---

## ğŸ“ˆ Results
ğŸ† **Public Score:** `0.395355497`  
ğŸ† **Private Score:** `0.414785791`  
ğŸ¥‡ **Leaderboard Position:** **Top 45**  

These results positioned the solution among the best-performing entries.

---

## âš ï¸ Weaknesses
- ğŸ“‰ Limited training data reduced adaptability to rare reasoning cases.
- ğŸ¤” Some answers lacked **context-specific depth**.
- ğŸ“ Long prompts sometimes produced **truncated responses**.

---

## ğŸš€ Future Improvements
To achieve **0.5+**, hereâ€™s whatâ€™s next:
1. ğŸ“š Add **medical domain knowledge bases**.
2. ğŸ¤– Fine-tune **larger transformer architectures**.
3. ğŸ¯ Use **prompt-engineering** for better context retention.
4. ğŸ“Š Data augmentation for underrepresented categories.
5. ğŸ§© Ensemble multiple architectures for robustness.

---

## ğŸ‘¨â€ğŸ’» Author
**Jackson Kahungu**  

ğŸ“… _Project Year: 2025_

---
âš  **Disclaimer**: For educational & research purposes only. Not for clinical decision-making.
